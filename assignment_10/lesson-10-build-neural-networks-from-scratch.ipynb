{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture-10 Build a neural network from sractch\n",
    "\n",
    "## Target: using python and numpy implement a neural network framework.\n",
    "\n",
    "---\n",
    "\n",
    "- forward: Function, how to calculate the inputs\n",
    "- backwards: Function, how to get the gradients when backpropogation\n",
    "- gradients: Mapper, the gradient map the this node of its inputs node\n",
    "- inputs: List, the input nodes of this node\n",
    "- outputs: List, the output node of this node\n",
    "\n",
    "---\n",
    "\n",
    "## 面向对象的方式来组织\n",
    "\n",
    "### 构建基类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    # 相当于构造器，对于每个节点有多个输入（List）和多个输出（List）\n",
    "    def __init__(self, inputs=[], name=''):\n",
    "        self.inputs = inputs  # 输入节点 list\n",
    "        self.outputs = []     # 输出节点 list\n",
    "        self.name = name      # 可以为每个节点起一个名字\n",
    "        self.gradients = {}   # 节点的梯度\n",
    "        self.value = None     # 节点的值，通过前向计算出来的\n",
    "        \n",
    "        for node in inputs:\n",
    "            node.outputs.append(self)\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplemented # NotImplemented 表示该函数是一个抽象函数，子类继承该类需要重写该函数\n",
    "        \n",
    "    def backward(self):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    # 该函数是为了打印类名和节点的名称\n",
    "    def __repr__(self):\n",
    "        return f'< {self.__class__.__name__}:{self.name} >'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input(Node) 表示 Input 继承 Node\n",
    "class Input(Node):\n",
    "    def __init__(self, name=''):\n",
    "        Node.__init__(self, inputs=[], name=name)\n",
    "        self.name = name\n",
    "    \n",
    "    def forward(self, value=None):\n",
    "        if value is not None: self.value = value\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {}\n",
    "        for output in self.outputs:\n",
    "            upstream_gradient = output.gradients[self]\n",
    "            self.gradients[self] = upstream_gradient ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias, name=''):\n",
    "        self.node_x = nodes\n",
    "        self.node_w = weights\n",
    "        self.node_b = bias\n",
    "        Node.__init__(self, inputs=[nodes, weights, bias], name=name)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.value = np.dot(self.node_x.value, self.node_w.value) + self.node_b.value\n",
    "        \n",
    "    def backward(self):\n",
    "        for output in self.outputs:\n",
    "            grad_cost = output.gradients[self]\n",
    "            self.gradients[self.node_w] = np.dot(self.node_x.value.T, grad_cost)\n",
    "            self.gradients[self.node_b] = np.sum(grad_cost * 1, axis=0, keepdims=False)\n",
    "            self.gradients[self.node_x] = np.dot(grad_cost, self.node_w.value.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self, node, name=''):\n",
    "        Node.__init__(self, [node], name=name)\n",
    "        self.node_x = node\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.value = self._sigmoid(self.node_x.value)\n",
    "    \n",
    "    def backward(self):\n",
    "        y = self.value\n",
    "        \n",
    "        self.partial = y * (1 - y) # 求偏导\n",
    "        \n",
    "        for output in self.outputs:\n",
    "            upstream_gradient = output.gradients[self]\n",
    "            self.gradients[self.node_x] = upstream_gradient * self.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y_true, y_hat, name=''):\n",
    "        self.y_true_node = y_true\n",
    "        self.y_hat_node = y_hat\n",
    "        Node.__init__(self, inputs=[y_true, y_hat], name=name)\n",
    "    \n",
    "    def forward(self):\n",
    "        y_true_flatten = self.y_true_node.value.reshape(-1, 1)\n",
    "        y_hat_flatten = self.y_hat_node.value.reshape(-1, 1)\n",
    "        self.diff = y_true_flatten - y_hat_flatten\n",
    "        self.value = np.mean(self.diff**2)\n",
    "        \n",
    "    def backward(self):\n",
    "        n = self.y_hat_node.value.shape[0]\n",
    "        self.gradients[self.y_true_node] = (2 / n) * self.diff\n",
    "        self.gradients[self.y_hat_node] =  (-2 / n) * self.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_one_batch(topological_sorted_graph):\n",
    "    # graph 是经过拓扑排序之后的一个list\n",
    "    for node in topological_sorted_graph:\n",
    "        node.forward()\n",
    "        \n",
    "    for node in topological_sorted_graph[::-1]:\n",
    "        node.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(data_with_value):\n",
    "    feed_dict = data_with_value \n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainable_nodes, learning_rate=1e-2):\n",
    "    for t in trainable_nodes:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "_X = data['data']\n",
    "_y = data['target']\n",
    "\n",
    "features = _X.shape[1]\n",
    "_X = (_X - _X.mean(axis=0)) / _X.std(axis=0)\n",
    "\n",
    "hidden_layer_1_nodes = 32\n",
    "hidden_layer_2_nodes = 32\n",
    "\n",
    "_W1, _b1 = np.random.randn(features, hidden_layer_1_nodes), np.zeros(hidden_layer_2_nodes)\n",
    "_W2, _b2 = np.random.randn(hidden_layer_2_nodes, 1), np.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Input(name='X'), Input(name='y')  # tensorflow -> placeholder\n",
    "W1, b1 = Input(name='W1'), Input(name='b1')\n",
    "W2, b2 = Input(name='W2'), Input(name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output = Linear(X, W1, b1, name='L1')\n",
    "sigmoid_output = Sigmoid(linear_output, name='sigmoid')\n",
    "yhat = Linear(sigmoid_output, W2, b2, name='L2')\n",
    "loss = MSE(y, yhat, name='MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node_with_value = {  # -> feed_dict \n",
    "    X: _X, \n",
    "    y: _y, \n",
    "    W1: _W1, \n",
    "    W2: _W2, \n",
    "    b1: _b1, \n",
    "    b2: _b2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = topological_sort(input_node_with_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[< Input:b2 >,\n",
       " < Input:b1 >,\n",
       " < Input:W1 >,\n",
       " < Input:W2 >,\n",
       " < Input:X >,\n",
       " < Input:y >,\n",
       " < Linear:L1 >,\n",
       " < Sigmoid:sigmoid >,\n",
       " < Linear:L2 >,\n",
       " < MSE:MSE >]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, loss = 10.428\n",
      "Epoch: 200, loss = 7.383\n",
      "Epoch: 300, loss = 6.161\n",
      "Epoch: 400, loss = 5.331\n",
      "Epoch: 500, loss = 4.670\n",
      "Epoch: 600, loss = 4.152\n",
      "Epoch: 700, loss = 3.730\n",
      "Epoch: 800, loss = 3.370\n",
      "Epoch: 900, loss = 3.059\n",
      "Epoch: 1000, loss = 2.791\n",
      "Epoch: 1100, loss = 2.562\n",
      "Epoch: 1200, loss = 2.371\n",
      "Epoch: 1300, loss = 2.212\n",
      "Epoch: 1400, loss = 2.076\n",
      "Epoch: 1500, loss = 1.960\n",
      "Epoch: 1600, loss = 1.858\n",
      "Epoch: 1700, loss = 1.766\n",
      "Epoch: 1800, loss = 1.683\n",
      "Epoch: 1900, loss = 1.607\n",
      "Epoch: 2000, loss = 1.538\n",
      "Epoch: 2100, loss = 1.473\n",
      "Epoch: 2200, loss = 1.413\n",
      "Epoch: 2300, loss = 1.357\n",
      "Epoch: 2400, loss = 1.305\n",
      "Epoch: 2500, loss = 1.256\n",
      "Epoch: 2600, loss = 1.210\n",
      "Epoch: 2700, loss = 1.167\n",
      "Epoch: 2800, loss = 1.127\n",
      "Epoch: 2900, loss = 1.090\n",
      "Epoch: 3000, loss = 1.056\n",
      "Epoch: 3100, loss = 1.025\n",
      "Epoch: 3200, loss = 0.995\n",
      "Epoch: 3300, loss = 0.968\n",
      "Epoch: 3400, loss = 0.943\n",
      "Epoch: 3500, loss = 0.920\n",
      "Epoch: 3600, loss = 0.899\n",
      "Epoch: 3700, loss = 0.880\n",
      "Epoch: 3800, loss = 0.862\n",
      "Epoch: 3900, loss = 0.846\n",
      "Epoch: 4000, loss = 0.831\n",
      "Epoch: 4100, loss = 0.817\n",
      "Epoch: 4200, loss = 0.803\n",
      "Epoch: 4300, loss = 0.791\n",
      "Epoch: 4400, loss = 0.778\n",
      "Epoch: 4500, loss = 0.767\n",
      "Epoch: 4600, loss = 0.755\n",
      "Epoch: 4700, loss = 0.744\n",
      "Epoch: 4800, loss = 0.732\n",
      "Epoch: 4900, loss = 0.721\n",
      "Epoch: 5000, loss = 0.711\n",
      "Epoch: 5100, loss = 0.700\n",
      "Epoch: 5200, loss = 0.690\n",
      "Epoch: 5300, loss = 0.680\n",
      "Epoch: 5400, loss = 0.670\n",
      "Epoch: 5500, loss = 0.661\n",
      "Epoch: 5600, loss = 0.652\n",
      "Epoch: 5700, loss = 0.644\n",
      "Epoch: 5800, loss = 0.635\n",
      "Epoch: 5900, loss = 0.628\n",
      "Epoch: 6000, loss = 0.620\n",
      "Epoch: 6100, loss = 0.613\n",
      "Epoch: 6200, loss = 0.606\n",
      "Epoch: 6300, loss = 0.599\n",
      "Epoch: 6400, loss = 0.593\n",
      "Epoch: 6500, loss = 0.586\n",
      "Epoch: 6600, loss = 0.580\n",
      "Epoch: 6700, loss = 0.574\n",
      "Epoch: 6800, loss = 0.569\n",
      "Epoch: 6900, loss = 0.563\n",
      "Epoch: 7000, loss = 0.558\n",
      "Epoch: 7100, loss = 0.552\n",
      "Epoch: 7200, loss = 0.547\n",
      "Epoch: 7300, loss = 0.542\n",
      "Epoch: 7400, loss = 0.537\n",
      "Epoch: 7500, loss = 0.532\n",
      "Epoch: 7600, loss = 0.528\n",
      "Epoch: 7700, loss = 0.523\n",
      "Epoch: 7800, loss = 0.518\n",
      "Epoch: 7900, loss = 0.514\n",
      "Epoch: 8000, loss = 0.509\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "epochs = 8000\n",
    "batch_size = 64\n",
    "n_samples = _X.shape[0]\n",
    "n_batches = (n_samples-1) // batch_size+1\n",
    "lr = 1e-2\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = .0\n",
    "    \n",
    "    for batch in range(n_batches):\n",
    "        #indices = np.random.choice(range(X_.shape[0]), size=10, replace=True)\n",
    "        #X_batch = X_[indices]\n",
    "        #y_batch = y_[indices]\n",
    "#         X_batch, y_batch = resample(_X, _y, n_samples=batch_size)\n",
    "        \n",
    "#         X.value = X_batch\n",
    "#         y.value = y_batch\n",
    "        \n",
    "#         input_node_with_value = {  # -> feed_dict \n",
    "#             X: X_batch, \n",
    "#             y: y_batch, \n",
    "#             W1: W1.value, \n",
    "#             W2: W2.value, \n",
    "#             b1: b1.value, \n",
    "#             b2: b2.value,\n",
    "#         }\n",
    "        \n",
    "#         graph = topological_sort(input_node_with_value)\n",
    "\n",
    "        start_i = batch * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb, yb = _X[start_i:end_i], _y[start_i:end_i]\n",
    "        X.value, y.value = xb, yb\n",
    "        \n",
    "        training_one_batch(graph)\n",
    "        \n",
    "        learning_rate = 1e-3\n",
    "        \n",
    "        sgd_update(trainable_nodes=[W1, W2, b1, b2], learning_rate=lr)\n",
    "        \n",
    "        loss += graph[-1].value\n",
    "        \n",
    "    if (i + 1) % 100 == 0:\n",
    "        print('Epoch: {}, loss = {:.3f}'.format(i+1, loss/n_batches))\n",
    "        losses.append(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11f804518>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
